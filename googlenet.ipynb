{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# googlenet\n",
    "\n",
    "\n",
    "rcnn\n",
    "데이터가 모자랄땐 pretrain모델을 사용해보는게 좋다\n",
    "-----\n",
    "\n",
    "22layers deep network 깊어진 레이어 \n",
    "\n",
    "1x1 conv 사용\n",
    "\n",
    "concatenated = 붙인거 ..\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv_Block(nn.Module):\n",
    "    def __init__(self,in_channels, out_channels,**kwargs) :\n",
    "        super(Conv_Block, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, **kwargs)\n",
    "        self.batch_norm = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.batch_norm(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv_Block(\n",
       "  (conv): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Conv_Block(3,64,kernel_size =1, stride =1, padding=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(nn.Module):\n",
    "    def __init__(self, in_channels, n1x1, n3x3_reduce, n3x3, n5x5_reduce, n5x5, pool_proj): \n",
    "        # n3x3_reduce는 3*3 conv전 1*1conv의 출력, 채널 reduce를 위해 사용\n",
    "        # pool_proj 마지막 풀링하고 1*1 하는거 . 프로젝션이라고 함\n",
    "        super(Inception, self).__init__()\n",
    "\n",
    "        self.branch_1 = Conv_Block(in_channels, n1x1, kernel_size = 1, stride=1, padding=0)\n",
    "\n",
    "        self.branch_2 = nn.Sequential(Conv_Block(in_channels, n3x3_reduce, kernel_size=1, stride=1, padding =0),\n",
    "                                        Conv_Block(n3x3_reduce, n3x3, kernel_size =1, stride=1, padding=0))\n",
    "\n",
    "        self.branch_3 = nn.Sequential(Conv_Block(in_channels,n5x5_reduce,kernel_size=1, stride=1, padding =0),\n",
    "                                        Conv_Block(n5x5_reduce,n5x5, kernel_size=5, stride=1, padding =2))\n",
    "\n",
    "        self.branch_4 = nn.Sequential(nn.MaxPool2d(kernel_size=3, stride=1, padding=1), # 맥스풀링은 피처맵사이즈 만 줄이니까 ,채널에 관한거는 인채널 아웃채널 업슴\n",
    "                                        Conv_Block(in_channels,pool_proj, kernel_size=1, stride=1, padding=0))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_1 = self.branch_1(x)\n",
    "        x_2 = self.branch_2(x)\n",
    "        x_3 = self.branch_3(x)\n",
    "        x_4 = self.branch_4(x)\n",
    "\n",
    "        return torch.cat([x_1,x_2,x_3,x_4], dim=1)\n",
    "        # 여기서는 채널을 합친다는 의미로 1이 된다. 그래서 feature맵 크기가 같아야한다 ! 그래서 위에서 f =f 다 하고 생각하면서 계산을했군요. \n",
    "        # feature맵 사이즈를 유지시켰음음 그게 concat하기 위해서였던것임\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b,c,h,w, 순서\n",
    "### depth = channel 여기서 depth는 채널\n",
    "\n",
    "# 모델의 depth = 깊이 레이어의 깊이\n",
    "# with를 키운다 = 채널을 키운다 고하네요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception_Aux(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(Inception_Aux,self).__init__()\n",
    "        self.avg_pool = nn.AvgPool2d(kernel_size=5, stride=3)\n",
    "        self.conv = Conv_Block(in_channels, 128, kernel_size =1, stride=1, padding=0)\n",
    "        self.fc1 = nn.Linear(in_features=128* 4*4, out_features=1024) # 2048은 128* 4*4\n",
    "        self.fc2 = nn.Linear(in_features=1024, out_features=10)\n",
    "    \n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.conv(x)\n",
    "\n",
    "        x= x.view(-1, 128*4*4) # 1d tensor로 만들어주기\n",
    "\n",
    "        x = F.dropout(F.relu(self.fc1(x)), p=0.7)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inception_Aux(\n",
       "  (avg_pool): AvgPool2d(kernel_size=5, stride=3, padding=0)\n",
       "  (conv): Conv_Block(\n",
       "    (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (batch_norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (fc1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Inception_Aux(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_m = Inception(192,64,96,128,16,32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]          12,352\n",
      "       BatchNorm2d-2         [-1, 64, 224, 224]             128\n",
      "              ReLU-3         [-1, 64, 224, 224]               0\n",
      "        Conv_Block-4         [-1, 64, 224, 224]               0\n",
      "            Conv2d-5         [-1, 96, 224, 224]          18,528\n",
      "       BatchNorm2d-6         [-1, 96, 224, 224]             192\n",
      "              ReLU-7         [-1, 96, 224, 224]               0\n",
      "        Conv_Block-8         [-1, 96, 224, 224]               0\n",
      "            Conv2d-9        [-1, 128, 224, 224]          12,416\n",
      "      BatchNorm2d-10        [-1, 128, 224, 224]             256\n",
      "             ReLU-11        [-1, 128, 224, 224]               0\n",
      "       Conv_Block-12        [-1, 128, 224, 224]               0\n",
      "           Conv2d-13         [-1, 16, 224, 224]           3,088\n",
      "      BatchNorm2d-14         [-1, 16, 224, 224]              32\n",
      "             ReLU-15         [-1, 16, 224, 224]               0\n",
      "       Conv_Block-16         [-1, 16, 224, 224]               0\n",
      "           Conv2d-17         [-1, 32, 224, 224]          12,832\n",
      "      BatchNorm2d-18         [-1, 32, 224, 224]              64\n",
      "             ReLU-19         [-1, 32, 224, 224]               0\n",
      "       Conv_Block-20         [-1, 32, 224, 224]               0\n",
      "        MaxPool2d-21        [-1, 192, 224, 224]               0\n",
      "           Conv2d-22         [-1, 32, 224, 224]           6,176\n",
      "      BatchNorm2d-23         [-1, 32, 224, 224]              64\n",
      "             ReLU-24         [-1, 32, 224, 224]               0\n",
      "       Conv_Block-25         [-1, 32, 224, 224]               0\n",
      "================================================================\n",
      "Total params: 66,128\n",
      "Trainable params: 66,128\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 36.75\n",
      "Forward/backward pass size (MB): 637.00\n",
      "Params size (MB): 0.25\n",
      "Estimated Total Size (MB): 674.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(i_m, (192,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_a = Inception_Aux(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         AvgPool2d-1            [-1, 512, 4, 4]               0\n",
      "            Conv2d-2            [-1, 128, 4, 4]          65,664\n",
      "       BatchNorm2d-3            [-1, 128, 4, 4]             256\n",
      "              ReLU-4            [-1, 128, 4, 4]               0\n",
      "        Conv_Block-5            [-1, 128, 4, 4]               0\n",
      "            Linear-6                 [-1, 1024]       2,098,176\n",
      "            Linear-7                   [-1, 10]          10,250\n",
      "================================================================\n",
      "Total params: 2,174,346\n",
      "Trainable params: 2,174,346\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.38\n",
      "Forward/backward pass size (MB): 0.13\n",
      "Params size (MB): 8.29\n",
      "Estimated Total Size (MB): 8.81\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(i_a,(512,14,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogleNet(nn.Module):\n",
    "    def __init__(self, train_):\n",
    "        super(GoogleNet, self).__init__()\n",
    "        self.training = train_\n",
    "\n",
    "        self.conv1= nn.Conv2d(in_channels=3,out_channels=64,kernel_size=7,stride=2,padding=3)\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64,kernel_size=1, stride=1, padding=0)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=192, kernel_size=3, stride=1 ,padding =1)\n",
    "        self.inc_3a = Inception(192, 64, 96, 128, 16, 32, 32) # 64+128+32+32\n",
    "        self.inc_3b = Inception(256, 128, 128, 192, 32, 96, 64)\n",
    "        \n",
    "        self.inc_4a = Inception(480, 192, 96, 208, 16, 48, 64)\n",
    "        self.inc_4b = Inception(512, 160, 112, 224, 24, 64, 64)\n",
    "        self.inc_4c = Inception(512, 128, 128, 256, 24, 64, 64)\n",
    "        self.inc_4d = Inception(512, 112, 144, 288, 32, 64, 64)\n",
    "        self.inc_4e = Inception(528, 256, 160, 320, 32, 128, 128)\n",
    "\n",
    "        self.inc_5a = Inception(832, 256, 160, 320, 32, 128, 128)\n",
    "        self.inc_5b = Inception(832, 384, 192, 384, 48, 128, 128)\n",
    "\n",
    "        self.aux_1 = Inception_Aux(512)\n",
    "        self.aux_2 = Inception_Aux(528)\n",
    "\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=3, stride=2, padding =1)\n",
    "        self.avg_pool = nn.AvgPool2d(kernel_size=7, stride=1) # 에버리지풀링은 이미지 사이즈1*!로 만드는거라 패딩업슴\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=1024, out_features=10)\n",
    "\n",
    "        self.lrn = nn.LocalResponseNorm(2)\n",
    "\n",
    "    def forward(self,x):\n",
    "        #\n",
    "        x = self.lrn(self.max_pool(F.relu(self.conv1(x))))\n",
    "\n",
    "        #\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.max_pool(self.lrn(F.relu(self.conv3(x))))\n",
    "       \n",
    "        #inception 3.\n",
    "        x = self.inc_3a(x)\n",
    "        x = self.inc_3b(x)\n",
    "        x = self.max_pool(x)\n",
    "\n",
    "        #inception 4.\n",
    "        x = self.inc_4a(x)\n",
    "\n",
    "        if self.training:\n",
    "            loss_1 = self.aux_1(x)\n",
    "        \n",
    "        x = self.inc_4b(x)\n",
    "        x = self.inc_4c(x)\n",
    "        x = self.inc_4d(x)\n",
    "\n",
    "        if self.training:\n",
    "            loss_2 = self.aux_2(x)\n",
    "\n",
    "        x = self.inc_4e(x)\n",
    "        x = self.max_pool(x)\n",
    "\n",
    "        # inception 5.\n",
    "        x = self.inc_5a(x)\n",
    "        x = self.inc_5b(x)\n",
    "\n",
    "        x = self.avg_pool(x)\n",
    "\n",
    "        x = x.view(-1,1024)\n",
    "\n",
    "        x = F.dropout(x, p=0.4)\n",
    "        x = self.fc1(x)\n",
    "\n",
    "        if self.training:\n",
    "            return x, loss_1, loss_2\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GoogleNet(train_=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,472\n",
      "         MaxPool2d-2           [-1, 64, 56, 56]               0\n",
      " LocalResponseNorm-3           [-1, 64, 56, 56]               0\n",
      "            Conv2d-4           [-1, 64, 56, 56]           4,160\n",
      "            Conv2d-5          [-1, 192, 56, 56]         110,784\n",
      " LocalResponseNorm-6          [-1, 192, 56, 56]               0\n",
      "         MaxPool2d-7          [-1, 192, 28, 28]               0\n",
      "            Conv2d-8           [-1, 64, 28, 28]          12,352\n",
      "       BatchNorm2d-9           [-1, 64, 28, 28]             128\n",
      "             ReLU-10           [-1, 64, 28, 28]               0\n",
      "       Conv_Block-11           [-1, 64, 28, 28]               0\n",
      "           Conv2d-12           [-1, 96, 28, 28]          18,528\n",
      "      BatchNorm2d-13           [-1, 96, 28, 28]             192\n",
      "             ReLU-14           [-1, 96, 28, 28]               0\n",
      "       Conv_Block-15           [-1, 96, 28, 28]               0\n",
      "           Conv2d-16          [-1, 128, 28, 28]          12,416\n",
      "      BatchNorm2d-17          [-1, 128, 28, 28]             256\n",
      "             ReLU-18          [-1, 128, 28, 28]               0\n",
      "       Conv_Block-19          [-1, 128, 28, 28]               0\n",
      "           Conv2d-20           [-1, 16, 28, 28]           3,088\n",
      "      BatchNorm2d-21           [-1, 16, 28, 28]              32\n",
      "             ReLU-22           [-1, 16, 28, 28]               0\n",
      "       Conv_Block-23           [-1, 16, 28, 28]               0\n",
      "           Conv2d-24           [-1, 32, 28, 28]          12,832\n",
      "      BatchNorm2d-25           [-1, 32, 28, 28]              64\n",
      "             ReLU-26           [-1, 32, 28, 28]               0\n",
      "       Conv_Block-27           [-1, 32, 28, 28]               0\n",
      "        MaxPool2d-28          [-1, 192, 28, 28]               0\n",
      "           Conv2d-29           [-1, 32, 28, 28]           6,176\n",
      "      BatchNorm2d-30           [-1, 32, 28, 28]              64\n",
      "             ReLU-31           [-1, 32, 28, 28]               0\n",
      "       Conv_Block-32           [-1, 32, 28, 28]               0\n",
      "        Inception-33          [-1, 256, 28, 28]               0\n",
      "           Conv2d-34          [-1, 128, 28, 28]          32,896\n",
      "      BatchNorm2d-35          [-1, 128, 28, 28]             256\n",
      "             ReLU-36          [-1, 128, 28, 28]               0\n",
      "       Conv_Block-37          [-1, 128, 28, 28]               0\n",
      "           Conv2d-38          [-1, 128, 28, 28]          32,896\n",
      "      BatchNorm2d-39          [-1, 128, 28, 28]             256\n",
      "             ReLU-40          [-1, 128, 28, 28]               0\n",
      "       Conv_Block-41          [-1, 128, 28, 28]               0\n",
      "           Conv2d-42          [-1, 192, 28, 28]          24,768\n",
      "      BatchNorm2d-43          [-1, 192, 28, 28]             384\n",
      "             ReLU-44          [-1, 192, 28, 28]               0\n",
      "       Conv_Block-45          [-1, 192, 28, 28]               0\n",
      "           Conv2d-46           [-1, 32, 28, 28]           8,224\n",
      "      BatchNorm2d-47           [-1, 32, 28, 28]              64\n",
      "             ReLU-48           [-1, 32, 28, 28]               0\n",
      "       Conv_Block-49           [-1, 32, 28, 28]               0\n",
      "           Conv2d-50           [-1, 96, 28, 28]          76,896\n",
      "      BatchNorm2d-51           [-1, 96, 28, 28]             192\n",
      "             ReLU-52           [-1, 96, 28, 28]               0\n",
      "       Conv_Block-53           [-1, 96, 28, 28]               0\n",
      "        MaxPool2d-54          [-1, 256, 28, 28]               0\n",
      "           Conv2d-55           [-1, 64, 28, 28]          16,448\n",
      "      BatchNorm2d-56           [-1, 64, 28, 28]             128\n",
      "             ReLU-57           [-1, 64, 28, 28]               0\n",
      "       Conv_Block-58           [-1, 64, 28, 28]               0\n",
      "        Inception-59          [-1, 480, 28, 28]               0\n",
      "        MaxPool2d-60          [-1, 480, 14, 14]               0\n",
      "           Conv2d-61          [-1, 192, 14, 14]          92,352\n",
      "      BatchNorm2d-62          [-1, 192, 14, 14]             384\n",
      "             ReLU-63          [-1, 192, 14, 14]               0\n",
      "       Conv_Block-64          [-1, 192, 14, 14]               0\n",
      "           Conv2d-65           [-1, 96, 14, 14]          46,176\n",
      "      BatchNorm2d-66           [-1, 96, 14, 14]             192\n",
      "             ReLU-67           [-1, 96, 14, 14]               0\n",
      "       Conv_Block-68           [-1, 96, 14, 14]               0\n",
      "           Conv2d-69          [-1, 208, 14, 14]          20,176\n",
      "      BatchNorm2d-70          [-1, 208, 14, 14]             416\n",
      "             ReLU-71          [-1, 208, 14, 14]               0\n",
      "       Conv_Block-72          [-1, 208, 14, 14]               0\n",
      "           Conv2d-73           [-1, 16, 14, 14]           7,696\n",
      "      BatchNorm2d-74           [-1, 16, 14, 14]              32\n",
      "             ReLU-75           [-1, 16, 14, 14]               0\n",
      "       Conv_Block-76           [-1, 16, 14, 14]               0\n",
      "           Conv2d-77           [-1, 48, 14, 14]          19,248\n",
      "      BatchNorm2d-78           [-1, 48, 14, 14]              96\n",
      "             ReLU-79           [-1, 48, 14, 14]               0\n",
      "       Conv_Block-80           [-1, 48, 14, 14]               0\n",
      "        MaxPool2d-81          [-1, 480, 14, 14]               0\n",
      "           Conv2d-82           [-1, 64, 14, 14]          30,784\n",
      "      BatchNorm2d-83           [-1, 64, 14, 14]             128\n",
      "             ReLU-84           [-1, 64, 14, 14]               0\n",
      "       Conv_Block-85           [-1, 64, 14, 14]               0\n",
      "        Inception-86          [-1, 512, 14, 14]               0\n",
      "        AvgPool2d-87            [-1, 512, 4, 4]               0\n",
      "           Conv2d-88            [-1, 128, 4, 4]          65,664\n",
      "      BatchNorm2d-89            [-1, 128, 4, 4]             256\n",
      "             ReLU-90            [-1, 128, 4, 4]               0\n",
      "       Conv_Block-91            [-1, 128, 4, 4]               0\n",
      "           Linear-92                 [-1, 1024]       2,098,176\n",
      "           Linear-93                   [-1, 10]          10,250\n",
      "    Inception_Aux-94                   [-1, 10]               0\n",
      "           Conv2d-95          [-1, 160, 14, 14]          82,080\n",
      "      BatchNorm2d-96          [-1, 160, 14, 14]             320\n",
      "             ReLU-97          [-1, 160, 14, 14]               0\n",
      "       Conv_Block-98          [-1, 160, 14, 14]               0\n",
      "           Conv2d-99          [-1, 112, 14, 14]          57,456\n",
      "     BatchNorm2d-100          [-1, 112, 14, 14]             224\n",
      "            ReLU-101          [-1, 112, 14, 14]               0\n",
      "      Conv_Block-102          [-1, 112, 14, 14]               0\n",
      "          Conv2d-103          [-1, 224, 14, 14]          25,312\n",
      "     BatchNorm2d-104          [-1, 224, 14, 14]             448\n",
      "            ReLU-105          [-1, 224, 14, 14]               0\n",
      "      Conv_Block-106          [-1, 224, 14, 14]               0\n",
      "          Conv2d-107           [-1, 24, 14, 14]          12,312\n",
      "     BatchNorm2d-108           [-1, 24, 14, 14]              48\n",
      "            ReLU-109           [-1, 24, 14, 14]               0\n",
      "      Conv_Block-110           [-1, 24, 14, 14]               0\n",
      "          Conv2d-111           [-1, 64, 14, 14]          38,464\n",
      "     BatchNorm2d-112           [-1, 64, 14, 14]             128\n",
      "            ReLU-113           [-1, 64, 14, 14]               0\n",
      "      Conv_Block-114           [-1, 64, 14, 14]               0\n",
      "       MaxPool2d-115          [-1, 512, 14, 14]               0\n",
      "          Conv2d-116           [-1, 64, 14, 14]          32,832\n",
      "     BatchNorm2d-117           [-1, 64, 14, 14]             128\n",
      "            ReLU-118           [-1, 64, 14, 14]               0\n",
      "      Conv_Block-119           [-1, 64, 14, 14]               0\n",
      "       Inception-120          [-1, 512, 14, 14]               0\n",
      "          Conv2d-121          [-1, 128, 14, 14]          65,664\n",
      "     BatchNorm2d-122          [-1, 128, 14, 14]             256\n",
      "            ReLU-123          [-1, 128, 14, 14]               0\n",
      "      Conv_Block-124          [-1, 128, 14, 14]               0\n",
      "          Conv2d-125          [-1, 128, 14, 14]          65,664\n",
      "     BatchNorm2d-126          [-1, 128, 14, 14]             256\n",
      "            ReLU-127          [-1, 128, 14, 14]               0\n",
      "      Conv_Block-128          [-1, 128, 14, 14]               0\n",
      "          Conv2d-129          [-1, 256, 14, 14]          33,024\n",
      "     BatchNorm2d-130          [-1, 256, 14, 14]             512\n",
      "            ReLU-131          [-1, 256, 14, 14]               0\n",
      "      Conv_Block-132          [-1, 256, 14, 14]               0\n",
      "          Conv2d-133           [-1, 24, 14, 14]          12,312\n",
      "     BatchNorm2d-134           [-1, 24, 14, 14]              48\n",
      "            ReLU-135           [-1, 24, 14, 14]               0\n",
      "      Conv_Block-136           [-1, 24, 14, 14]               0\n",
      "          Conv2d-137           [-1, 64, 14, 14]          38,464\n",
      "     BatchNorm2d-138           [-1, 64, 14, 14]             128\n",
      "            ReLU-139           [-1, 64, 14, 14]               0\n",
      "      Conv_Block-140           [-1, 64, 14, 14]               0\n",
      "       MaxPool2d-141          [-1, 512, 14, 14]               0\n",
      "          Conv2d-142           [-1, 64, 14, 14]          32,832\n",
      "     BatchNorm2d-143           [-1, 64, 14, 14]             128\n",
      "            ReLU-144           [-1, 64, 14, 14]               0\n",
      "      Conv_Block-145           [-1, 64, 14, 14]               0\n",
      "       Inception-146          [-1, 512, 14, 14]               0\n",
      "          Conv2d-147          [-1, 112, 14, 14]          57,456\n",
      "     BatchNorm2d-148          [-1, 112, 14, 14]             224\n",
      "            ReLU-149          [-1, 112, 14, 14]               0\n",
      "      Conv_Block-150          [-1, 112, 14, 14]               0\n",
      "          Conv2d-151          [-1, 144, 14, 14]          73,872\n",
      "     BatchNorm2d-152          [-1, 144, 14, 14]             288\n",
      "            ReLU-153          [-1, 144, 14, 14]               0\n",
      "      Conv_Block-154          [-1, 144, 14, 14]               0\n",
      "          Conv2d-155          [-1, 288, 14, 14]          41,760\n",
      "     BatchNorm2d-156          [-1, 288, 14, 14]             576\n",
      "            ReLU-157          [-1, 288, 14, 14]               0\n",
      "      Conv_Block-158          [-1, 288, 14, 14]               0\n",
      "          Conv2d-159           [-1, 32, 14, 14]          16,416\n",
      "     BatchNorm2d-160           [-1, 32, 14, 14]              64\n",
      "            ReLU-161           [-1, 32, 14, 14]               0\n",
      "      Conv_Block-162           [-1, 32, 14, 14]               0\n",
      "          Conv2d-163           [-1, 64, 14, 14]          51,264\n",
      "     BatchNorm2d-164           [-1, 64, 14, 14]             128\n",
      "            ReLU-165           [-1, 64, 14, 14]               0\n",
      "      Conv_Block-166           [-1, 64, 14, 14]               0\n",
      "       MaxPool2d-167          [-1, 512, 14, 14]               0\n",
      "          Conv2d-168           [-1, 64, 14, 14]          32,832\n",
      "     BatchNorm2d-169           [-1, 64, 14, 14]             128\n",
      "            ReLU-170           [-1, 64, 14, 14]               0\n",
      "      Conv_Block-171           [-1, 64, 14, 14]               0\n",
      "       Inception-172          [-1, 528, 14, 14]               0\n",
      "       AvgPool2d-173            [-1, 528, 4, 4]               0\n",
      "          Conv2d-174            [-1, 128, 4, 4]          67,712\n",
      "     BatchNorm2d-175            [-1, 128, 4, 4]             256\n",
      "            ReLU-176            [-1, 128, 4, 4]               0\n",
      "      Conv_Block-177            [-1, 128, 4, 4]               0\n",
      "          Linear-178                 [-1, 1024]       2,098,176\n",
      "          Linear-179                   [-1, 10]          10,250\n",
      "   Inception_Aux-180                   [-1, 10]               0\n",
      "          Conv2d-181          [-1, 256, 14, 14]         135,424\n",
      "     BatchNorm2d-182          [-1, 256, 14, 14]             512\n",
      "            ReLU-183          [-1, 256, 14, 14]               0\n",
      "      Conv_Block-184          [-1, 256, 14, 14]               0\n",
      "          Conv2d-185          [-1, 160, 14, 14]          84,640\n",
      "     BatchNorm2d-186          [-1, 160, 14, 14]             320\n",
      "            ReLU-187          [-1, 160, 14, 14]               0\n",
      "      Conv_Block-188          [-1, 160, 14, 14]               0\n",
      "          Conv2d-189          [-1, 320, 14, 14]          51,520\n",
      "     BatchNorm2d-190          [-1, 320, 14, 14]             640\n",
      "            ReLU-191          [-1, 320, 14, 14]               0\n",
      "      Conv_Block-192          [-1, 320, 14, 14]               0\n",
      "          Conv2d-193           [-1, 32, 14, 14]          16,928\n",
      "     BatchNorm2d-194           [-1, 32, 14, 14]              64\n",
      "            ReLU-195           [-1, 32, 14, 14]               0\n",
      "      Conv_Block-196           [-1, 32, 14, 14]               0\n",
      "          Conv2d-197          [-1, 128, 14, 14]         102,528\n",
      "     BatchNorm2d-198          [-1, 128, 14, 14]             256\n",
      "            ReLU-199          [-1, 128, 14, 14]               0\n",
      "      Conv_Block-200          [-1, 128, 14, 14]               0\n",
      "       MaxPool2d-201          [-1, 528, 14, 14]               0\n",
      "          Conv2d-202          [-1, 128, 14, 14]          67,712\n",
      "     BatchNorm2d-203          [-1, 128, 14, 14]             256\n",
      "            ReLU-204          [-1, 128, 14, 14]               0\n",
      "      Conv_Block-205          [-1, 128, 14, 14]               0\n",
      "       Inception-206          [-1, 832, 14, 14]               0\n",
      "       MaxPool2d-207            [-1, 832, 7, 7]               0\n",
      "          Conv2d-208            [-1, 256, 7, 7]         213,248\n",
      "     BatchNorm2d-209            [-1, 256, 7, 7]             512\n",
      "            ReLU-210            [-1, 256, 7, 7]               0\n",
      "      Conv_Block-211            [-1, 256, 7, 7]               0\n",
      "          Conv2d-212            [-1, 160, 7, 7]         133,280\n",
      "     BatchNorm2d-213            [-1, 160, 7, 7]             320\n",
      "            ReLU-214            [-1, 160, 7, 7]               0\n",
      "      Conv_Block-215            [-1, 160, 7, 7]               0\n",
      "          Conv2d-216            [-1, 320, 7, 7]          51,520\n",
      "     BatchNorm2d-217            [-1, 320, 7, 7]             640\n",
      "            ReLU-218            [-1, 320, 7, 7]               0\n",
      "      Conv_Block-219            [-1, 320, 7, 7]               0\n",
      "          Conv2d-220             [-1, 32, 7, 7]          26,656\n",
      "     BatchNorm2d-221             [-1, 32, 7, 7]              64\n",
      "            ReLU-222             [-1, 32, 7, 7]               0\n",
      "      Conv_Block-223             [-1, 32, 7, 7]               0\n",
      "          Conv2d-224            [-1, 128, 7, 7]         102,528\n",
      "     BatchNorm2d-225            [-1, 128, 7, 7]             256\n",
      "            ReLU-226            [-1, 128, 7, 7]               0\n",
      "      Conv_Block-227            [-1, 128, 7, 7]               0\n",
      "       MaxPool2d-228            [-1, 832, 7, 7]               0\n",
      "          Conv2d-229            [-1, 128, 7, 7]         106,624\n",
      "     BatchNorm2d-230            [-1, 128, 7, 7]             256\n",
      "            ReLU-231            [-1, 128, 7, 7]               0\n",
      "      Conv_Block-232            [-1, 128, 7, 7]               0\n",
      "       Inception-233            [-1, 832, 7, 7]               0\n",
      "          Conv2d-234            [-1, 384, 7, 7]         319,872\n",
      "     BatchNorm2d-235            [-1, 384, 7, 7]             768\n",
      "            ReLU-236            [-1, 384, 7, 7]               0\n",
      "      Conv_Block-237            [-1, 384, 7, 7]               0\n",
      "          Conv2d-238            [-1, 192, 7, 7]         159,936\n",
      "     BatchNorm2d-239            [-1, 192, 7, 7]             384\n",
      "            ReLU-240            [-1, 192, 7, 7]               0\n",
      "      Conv_Block-241            [-1, 192, 7, 7]               0\n",
      "          Conv2d-242            [-1, 384, 7, 7]          74,112\n",
      "     BatchNorm2d-243            [-1, 384, 7, 7]             768\n",
      "            ReLU-244            [-1, 384, 7, 7]               0\n",
      "      Conv_Block-245            [-1, 384, 7, 7]               0\n",
      "          Conv2d-246             [-1, 48, 7, 7]          39,984\n",
      "     BatchNorm2d-247             [-1, 48, 7, 7]              96\n",
      "            ReLU-248             [-1, 48, 7, 7]               0\n",
      "      Conv_Block-249             [-1, 48, 7, 7]               0\n",
      "          Conv2d-250            [-1, 128, 7, 7]         153,728\n",
      "     BatchNorm2d-251            [-1, 128, 7, 7]             256\n",
      "            ReLU-252            [-1, 128, 7, 7]               0\n",
      "      Conv_Block-253            [-1, 128, 7, 7]               0\n",
      "       MaxPool2d-254            [-1, 832, 7, 7]               0\n",
      "          Conv2d-255            [-1, 128, 7, 7]         106,624\n",
      "     BatchNorm2d-256            [-1, 128, 7, 7]             256\n",
      "            ReLU-257            [-1, 128, 7, 7]               0\n",
      "      Conv_Block-258            [-1, 128, 7, 7]               0\n",
      "       Inception-259           [-1, 1024, 7, 7]               0\n",
      "       AvgPool2d-260           [-1, 1024, 1, 1]               0\n",
      "          Linear-261                   [-1, 10]          10,250\n",
      "================================================================\n",
      "Total params: 7,690,158\n",
      "Trainable params: 7,690,158\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 88.35\n",
      "Params size (MB): 29.34\n",
      "Estimated Total Size (MB): 118.26\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env2022",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a8c34bf83bfc7bcd2aa6e2ab268591c38c42047be2677c81ba7101594e9edef1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
